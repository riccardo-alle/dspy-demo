{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poznański Horyzont Danych Meetup - 10.12.2024\n",
    "# DSPy Introduction\n",
    "\n",
    "Tutorial inspired by [dspy/examples/agents/multi_agent.ipynb](https://github.com/stanfordnlp/dspy/blob/main/examples/agents/multi_agent.ipynb)\n",
    "\n",
    "If you've ever felt intimidated by DSPy, don't worry—it might look complex at first glance, but it's actually quite approachable. This tutorial will walk you through the process of building a  project, providing a clear, step-by-step approach to understanding and implementing DSPy concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links and concepts before starting to rock DSPy... 🚀\n",
    "\n",
    "- I strongly recommend reading the [DSPy Cheatsheet](https://dspy.ai/cheatsheet/) it will help you with quick start;\n",
    "\n",
    "- Do you want know more about DSPY optimizers? Read [this guide](https://dspy.ai/learn/optimization/optimizers/?h=optimizers)!\n",
    "\n",
    "- You find tons of tutorials in [dpsy/examples](https://github.com/stanfordnlp/dspy/blob/main/examples) folder;\n",
    "\n",
    "- Remember the DSPy \"scientific method\":\n",
    "  - **Define your task**: what is the input? What is the expected output?\n",
    "  - **Define your pipeline**: do we need ChainOfThoughts? Do we need any external tool, like a retriever?\n",
    "  - **Explore a few examples**: explore both input and output. It might be worth to annotate few examples for debugging purposes.\n",
    "  - **Define your data**: define training and validation sets;\n",
    "  - **Define your metric**: define an objective metric you will use to evaluate your programs. You don't have it? You can ask an LLM to evaluate for you!\n",
    "  - **Collect preliminary \"zero-shot\" evaluations**: try out your program without optimization to get baseline results;\n",
    "  - **Compile with a DSPy optimizer**: start with FewShot optimizers and follow with more complex ones, like MIPRO, COPROv2...\n",
    "  - **Iterate**: iterate the steps above, until you are satisfief with the results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShot, LabeledFewShot, MIPROv2\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# load your environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# azure-openai model deployment\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_VERSION = os.getenv(\"AZURE_OPENAI_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "For this tutorial, we are going to use the [HotPotQA dataset](https://hotpotqa.github.io/). The task for the LLM is multi-hop question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HotPotQA(train_seed=1, train_size=150, eval_seed=2023, dev_size=50, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Inputs\n",
    "\n",
    "It's crucial to inform DSPy which attributes serve as inputs for our model. We accomplish this using the `.with_inputs()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [x.with_inputs('question') for x in dataset.train]\n",
    "dev_set = [x.with_inputs('question') for x in dataset.dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPy setup\n",
    "\n",
    "DSPy is designed to be compatible with a variety of language models and their respective clients ([click here](https://dspy.ai/learn/programming/language_models) for a complete guide to all supported LLMs). For this tutorial, we will primarily utilize GPT-4 through the Azure client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = dspy.AzureOpenAI(\n",
    "    api_base=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_VERSION,\n",
    "    deployment_id=AZURE_OPENAI_DEPLOYMENT,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    # Specify the models parameter\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "retriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(lm=llm, rm=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Signatures and Modules\n",
    "\n",
    "\n",
    "### Core DSPy Components\n",
    "\n",
    "[dspy.Signature](https://dspy.ai/learn/programming/signatures/) and [dspy.Module](https://dspy.ai/learn/programming/modules/) are fundamental building blocks for DSPy programs:\n",
    "\n",
    "- **Signature**: A declarative specification of the input/output behavior of a DSPy module.\n",
    "- **Module**: A building block for programs that leverage Language Models (LMs).\n",
    "\n",
    "### Types of DSPy Modules\n",
    "\n",
    "DSPy offers various module types, each serving different purposes:\n",
    "\n",
    "1. [dspy.Predict](https://dspy-docs.vercel.app/api/modules/Predict)\n",
    "   - Basic predictor\n",
    "   - Maintains the original signature\n",
    "   - Handles key forms of learning (storing instructions, demonstrations, and LM updates)\n",
    "   - Most similar to direct LM usage\n",
    "\n",
    "2. [dspy.ChainOfThought](https://dspy-docs.vercel.app/api/modules/ChainOfThought)\n",
    "   - Enhances the LM to think step-by-step before producing the final response\n",
    "   - Modifies the signature to incorporate intermediate reasoning steps\n",
    "     \n",
    "\n",
    "3. [Additional Advanced Modules](https://dspy-docs.vercel.app/api/category/modules)\n",
    "   - DSPy library offers a range of more specialized modules for complex tasks;\n",
    "   - In this talk, we will explore the [ReAct](https://dspy.ai/deep-dive/modules/react/) module.\n",
    "\n",
    "### Recommendation for starting\n",
    "\n",
    "For those new to DSPy, it's advisable to start with `dspy.Predict`. Its simplicity makes it ideal for understanding the basics of DSPy operation. Once you've successfully implemented your program using `dspy.Predict`, you can explore more advanced modules like `dspy.ChainOfThought` to potentially enhance your model's performance.\n",
    "\n",
    "For an overview of other prompting techniques beyond zero-shot learning, refer to the [Prompting Guide](https://www.promptingguide.ai/techniques). This resource covers various methods that can enhance your DSPy applications as you progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    # [OPTIONAL]: Clarify something about the nature of the task expressed below as a docstring.\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    # Supply hints on the nature of an input field, expressed as a desc keyword argument for dspy.InputField.\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['At My Window (album) | At My Window is an album released by Folk/country singer-songwriter Townes Van Zandt in 1987. This was Van Zandt\\'s first studio album in the nine years that followed 1978\\'s \"Flyin\\' Shoes\", and his only studio album recorded in the 1980s. Although the songwriter had become less prolific, this release showed that the quality of his material remained high.', 'Little Window | Little Window is the debut album of American singer-songwriter Baby Dee. The album was released in 2002 on the Durtro label. It was produced, composed, and performed entirely by Dee.', 'Windows and Walls | Windows and Walls is the eighth album by American singer-songwriter Dan Fogelberg, released in 1984 (see 1984 in music). The first single, \"The Language of Love\", reached 13 on the U.S. \"Billboard\" Hot 100 chart. Although the follow-up, \"Believe in Me\", missed the Top 40 of the pop chart, peaking at No. 48, it became the singer\\'s fourth No. 1 song on the \"Billboard\" adult contemporary chart.'],\n",
       "    answer='Townes Van Zandt',\n",
       "    rationale='identify the artist associated with the album \"At My Window.\" The context states that it was released by Folk/country singer-songwriter Townes Van Zandt.'\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = BaselineRAG()\n",
    "\n",
    "baseline(train_set[0].question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a positive match when:\n",
    "# (generated answer and true answer match exactly) AND (the retrieved context does actually contain that answer)\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hotpot = Evaluate(\n",
    "    devset=dev_set,\n",
    "    metric=validate_context_and_answer,\n",
    "    num_threads=8,\n",
    "    display_progress=True,\n",
    "    display_table=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.00 / 50 (36.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 169.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:04:34 INFO dspy.evaluate.evaluate: Average Metric: 18 / 50 (36.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>gold_titles</th>\n",
       "      <th>context</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>rationale</th>\n",
       "      <th>validate_context_and_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td>no</td>\n",
       "      <td>{Cangzhou, Qionghai}</td>\n",
       "      <td>['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...</td>\n",
       "      <td>No, only Cangzhou.</td>\n",
       "      <td>determine the location of both cities. We know that Cangzhou is in...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who conducts the draft in which Marc-Andre Fleury was drafted to t...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>{2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}</td>\n",
       "      <td>['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...</td>\n",
       "      <td>NHL</td>\n",
       "      <td>identify the entity responsible for the draft in question. We know...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wings entered a new era, following the retirement of which Can...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>{Steve Yzerman, 2006–07 Detroit Red Wings season}</td>\n",
       "      <td>['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>identify the player mentioned in the context. We see that Steve Yz...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What river is near the Crichton Collegiate Church?</td>\n",
       "      <td>the River Tyne</td>\n",
       "      <td>{Crichton Collegiate Church, Crichton Castle}</td>\n",
       "      <td>[\"Crichton Collegiate Church | Crichton Collegiate Church is situa...</td>\n",
       "      <td>River Tyne</td>\n",
       "      <td>identify the river associated with Crichton Collegiate Church. The...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...</td>\n",
       "      <td>King Alfred the Great</td>\n",
       "      <td>{Æthelweard (son of Alfred), Ealhswith}</td>\n",
       "      <td>[\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...</td>\n",
       "      <td>Alfred the Great</td>\n",
       "      <td>identify the king who was the father of Æthelweard. Ealhswith is k...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Newark Airport Exchange is at the northern edge of an airport ...</td>\n",
       "      <td>Port Authority of New York and New Jersey</td>\n",
       "      <td>{Newark Airport Interchange, Newark Liberty International Airport}</td>\n",
       "      <td>['Newark Airport Interchange | The Newark Airport Interchange is a...</td>\n",
       "      <td>Port Authority of New York and New Jersey</td>\n",
       "      <td>identify the operator of Newark Liberty International Airport. We ...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Where did an event take place resulting in a win during a domestic...</td>\n",
       "      <td>Bundesliga</td>\n",
       "      <td>{2005–06 FC Bayern Munich season, Claudio Pizarro}</td>\n",
       "      <td>['List of Peru international footballers | Peru took part in the i...</td>\n",
       "      <td>Peru</td>\n",
       "      <td>produce the answer. We know that the context mentions important Pe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Are both Chico Municipal Airport and William R. Fairchild Internat...</td>\n",
       "      <td>no</td>\n",
       "      <td>{Chico Municipal Airport, William R. Fairchild International Airport}</td>\n",
       "      <td>['William R. Fairchild International Airport | William R. Fairchil...</td>\n",
       "      <td>No</td>\n",
       "      <td>determine the locations of the airports. William R. Fairchild Inte...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In which Maine county is Fort Pownall located?</td>\n",
       "      <td>Waldo County, Maine</td>\n",
       "      <td>{Fort Pownall, Stockton Springs, Maine}</td>\n",
       "      <td>[\"Fort Pownall | Fort Pownall was a British fortification built du...</td>\n",
       "      <td>Waldo County</td>\n",
       "      <td>identify the location of Fort Pownall. The context specifies that ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which 90s rock band has more recently reformed, Gene or The Afghan...</td>\n",
       "      <td>The Afghan Whigs</td>\n",
       "      <td>{The Afghan Whigs, Gene (band)}</td>\n",
       "      <td>['The Afghan Whigs | The Afghan Whigs are an American rock band fr...</td>\n",
       "      <td>The Afghan Whigs</td>\n",
       "      <td>compare the two bands' timelines. The Afghan Whigs were originally...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0         Are both Cangzhou and Qionghai in the Hebei province of China?   \n",
       "1  Who conducts the draft in which Marc-Andre Fleury was drafted to t...   \n",
       "2  The Wings entered a new era, following the retirement of which Can...   \n",
       "3                     What river is near the Crichton Collegiate Church?   \n",
       "4  In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...   \n",
       "5  The Newark Airport Exchange is at the northern edge of an airport ...   \n",
       "6  Where did an event take place resulting in a win during a domestic...   \n",
       "7  Are both Chico Municipal Airport and William R. Fairchild Internat...   \n",
       "8                         In which Maine county is Fort Pownall located?   \n",
       "9  Which 90s rock band has more recently reformed, Gene or The Afghan...   \n",
       "\n",
       "                              example_answer  \\\n",
       "0                                         no   \n",
       "1                     National Hockey League   \n",
       "2                              Steve Yzerman   \n",
       "3                             the River Tyne   \n",
       "4                      King Alfred the Great   \n",
       "5  Port Authority of New York and New Jersey   \n",
       "6                                 Bundesliga   \n",
       "7                                         no   \n",
       "8                        Waldo County, Maine   \n",
       "9                           The Afghan Whigs   \n",
       "\n",
       "                                                             gold_titles  \\\n",
       "0                                                   {Cangzhou, Qionghai}   \n",
       "1         {2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}   \n",
       "2                      {Steve Yzerman, 2006–07 Detroit Red Wings season}   \n",
       "3                          {Crichton Collegiate Church, Crichton Castle}   \n",
       "4                                {Æthelweard (son of Alfred), Ealhswith}   \n",
       "5     {Newark Airport Interchange, Newark Liberty International Airport}   \n",
       "6                     {2005–06 FC Bayern Munich season, Claudio Pizarro}   \n",
       "7  {Chico Municipal Airport, William R. Fairchild International Airport}   \n",
       "8                                {Fort Pownall, Stockton Springs, Maine}   \n",
       "9                                        {The Afghan Whigs, Gene (band)}   \n",
       "\n",
       "                                                                 context  \\\n",
       "0  ['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...   \n",
       "1  ['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...   \n",
       "2  ['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...   \n",
       "3  [\"Crichton Collegiate Church | Crichton Collegiate Church is situa...   \n",
       "4  [\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...   \n",
       "5  ['Newark Airport Interchange | The Newark Airport Interchange is a...   \n",
       "6  ['List of Peru international footballers | Peru took part in the i...   \n",
       "7  ['William R. Fairchild International Airport | William R. Fairchil...   \n",
       "8  [\"Fort Pownall | Fort Pownall was a British fortification built du...   \n",
       "9  ['The Afghan Whigs | The Afghan Whigs are an American rock band fr...   \n",
       "\n",
       "                                 pred_answer  \\\n",
       "0                         No, only Cangzhou.   \n",
       "1                                        NHL   \n",
       "2                              Steve Yzerman   \n",
       "3                                 River Tyne   \n",
       "4                           Alfred the Great   \n",
       "5  Port Authority of New York and New Jersey   \n",
       "6                                       Peru   \n",
       "7                                         No   \n",
       "8                               Waldo County   \n",
       "9                           The Afghan Whigs   \n",
       "\n",
       "                                                               rationale  \\\n",
       "0  determine the location of both cities. We know that Cangzhou is in...   \n",
       "1  identify the entity responsible for the draft in question. We know...   \n",
       "2  identify the player mentioned in the context. We see that Steve Yz...   \n",
       "3  identify the river associated with Crichton Collegiate Church. The...   \n",
       "4  identify the king who was the father of Æthelweard. Ealhswith is k...   \n",
       "5  identify the operator of Newark Liberty International Airport. We ...   \n",
       "6  produce the answer. We know that the context mentions important Pe...   \n",
       "7  determine the locations of the airports. William R. Fairchild Inte...   \n",
       "8  identify the location of Fort Pownall. The context specifies that ...   \n",
       "9  compare the two bands' timelines. The Afghan Whigs were originally...   \n",
       "\n",
       "  validate_context_and_answer  \n",
       "0                              \n",
       "1                              \n",
       "2                   ✔️ [True]  \n",
       "3                   ✔️ [True]  \n",
       "4                              \n",
       "5                   ✔️ [True]  \n",
       "6                              \n",
       "7                   ✔️ [True]  \n",
       "8                              \n",
       "9                   ✔️ [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 40 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_hotpot(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now... some DSPy magic ✨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a ReAct module\n",
    "\n",
    "The ReAct framework combines reasoning (thinking) and acting (taking actions) in LLMs.\n",
    "It alternates between reasoning about the problem and performing actions, like retrieving information or interacting with an environment, to dynamically adapt as new information becomes available.\n",
    "\n",
    "<center><img src=\"assets/react-schema.png\" width=\"1000\" align=\"center\"><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought_0': 'At My Window was released by the American singer-songwriter Joni Mitchell.\\n\\nNext Thought: I need to confirm the artist for the song \"At My Window\" to ensure accuracy.',\n",
       " 'tool_name_0': 'Search',\n",
       " 'tool_args_0': '{\"query\": \"At My Window American singer-songwriter\"}',\n",
       " 'observation_0': Prediction(\n",
       "     passages=['At My Window (album) | At My Window is an album released by Folk/country singer-songwriter Townes Van Zandt in 1987. This was Van Zandt\\'s first studio album in the nine years that followed 1978\\'s \"Flyin\\' Shoes\", and his only studio album recorded in the 1980s. Although the songwriter had become less prolific, this release showed that the quality of his material remained high.']\n",
       " ),\n",
       " 'thought_1': 'It seems that the song \"At My Window\" is actually attributed to Townes Van Zandt, not Joni Mitchell. I need to update my answer accordingly.',\n",
       " 'tool_name_1': 'finish',\n",
       " 'tool_args_1': '{}',\n",
       " 'observation_1': 'Completed.'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = train_set[0].question\n",
    "result = agent(question=question)\n",
    "result.trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 50 (44.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 32.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:08:33 INFO dspy.evaluate.evaluate: Average Metric: 22 / 50 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>gold_titles</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>rationale</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td>no</td>\n",
       "      <td>{Cangzhou, Qionghai}</td>\n",
       "      <td>{'thought_0': 'Cangzhou is located in Hebei province, while Qiongh...</td>\n",
       "      <td>determine whether both cities are in the Hebei province. We start ...</td>\n",
       "      <td>No, they are not both in the Hebei province of China.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who conducts the draft in which Marc-Andre Fleury was drafted to t...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>{2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}</td>\n",
       "      <td>{'thought_0': \"The question asks about the draft process for Marc-...</td>\n",
       "      <td>determine who conducted the draft in which Marc-Andre Fleury was d...</td>\n",
       "      <td>The NHL conducted the draft in which Marc-Andre Fleury was drafted...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wings entered a new era, following the retirement of which Can...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>{Steve Yzerman, 2006–07 Detroit Red Wings season}</td>\n",
       "      <td>{'thought_0': \"The Wings' new era likely began after a significant...</td>\n",
       "      <td>produce the answer. We started by identifying the context of the q...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What river is near the Crichton Collegiate Church?</td>\n",
       "      <td>the River Tyne</td>\n",
       "      <td>{Crichton Collegiate Church, Crichton Castle}</td>\n",
       "      <td>{'thought_0': 'Question: What river is near the Crichton Collegiat...</td>\n",
       "      <td>determine the river near the Crichton Collegiate Church. I started...</td>\n",
       "      <td>River Tyne</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...</td>\n",
       "      <td>King Alfred the Great</td>\n",
       "      <td>{Æthelweard (son of Alfred), Ealhswith}</td>\n",
       "      <td>{'thought_0': \"Question: In the 10th Century A.D. Ealhswith had a ...</td>\n",
       "      <td>determine which English king Ealhswith was married to and subseque...</td>\n",
       "      <td>King Alfred the Great</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0         Are both Cangzhou and Qionghai in the Hebei province of China?   \n",
       "1  Who conducts the draft in which Marc-Andre Fleury was drafted to t...   \n",
       "2  The Wings entered a new era, following the retirement of which Can...   \n",
       "3                     What river is near the Crichton Collegiate Church?   \n",
       "4  In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...   \n",
       "\n",
       "           example_answer  \\\n",
       "0                      no   \n",
       "1  National Hockey League   \n",
       "2           Steve Yzerman   \n",
       "3          the River Tyne   \n",
       "4   King Alfred the Great   \n",
       "\n",
       "                                                      gold_titles  \\\n",
       "0                                            {Cangzhou, Qionghai}   \n",
       "1  {2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}   \n",
       "2               {Steve Yzerman, 2006–07 Detroit Red Wings season}   \n",
       "3                   {Crichton Collegiate Church, Crichton Castle}   \n",
       "4                         {Æthelweard (son of Alfred), Ealhswith}   \n",
       "\n",
       "                                                              trajectory  \\\n",
       "0  {'thought_0': 'Cangzhou is located in Hebei province, while Qiongh...   \n",
       "1  {'thought_0': \"The question asks about the draft process for Marc-...   \n",
       "2  {'thought_0': \"The Wings' new era likely began after a significant...   \n",
       "3  {'thought_0': 'Question: What river is near the Crichton Collegiat...   \n",
       "4  {'thought_0': \"Question: In the 10th Century A.D. Ealhswith had a ...   \n",
       "\n",
       "                                                               rationale  \\\n",
       "0  determine whether both cities are in the Hebei province. We start ...   \n",
       "1  determine who conducted the draft in which Marc-Andre Fleury was d...   \n",
       "2  produce the answer. We started by identifying the context of the q...   \n",
       "3  determine the river near the Crichton Collegiate Church. I started...   \n",
       "4  determine which English king Ealhswith was married to and subseque...   \n",
       "\n",
       "                                                             pred_answer  \\\n",
       "0                  No, they are not both in the Hebei province of China.   \n",
       "1  The NHL conducted the draft in which Marc-Andre Fleury was drafted...   \n",
       "2                                                          Steve Yzerman   \n",
       "3                                                             River Tyne   \n",
       "4                                                  King Alfred the Great   \n",
       "\n",
       "  answer_exact_match  \n",
       "0                     \n",
       "1                     \n",
       "2          ✔️ [True]  \n",
       "3          ✔️ [True]  \n",
       "4          ✔️ [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(num_threads=8, display_progress=True, display_table=5)\n",
    "evaluate = Evaluate(devset=dev_set, metric=dspy.evaluate.answer_exact_match, **config)\n",
    "\n",
    "evaluate(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Optimizers - Automatic Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These optimizers extend the signature by automatically generating and including optimized examples within the prompt sent to the model, implementing few-shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabeledFewShot\n",
    "\n",
    "Simply constructs few-shot examples (demos) from provided labeled input and output data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 50 (56.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 293.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:27:02 INFO dspy.evaluate.evaluate: Average Metric: 28 / 50 (56.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>gold_titles</th>\n",
       "      <th>context</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>rationale</th>\n",
       "      <th>answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td>no</td>\n",
       "      <td>{Cangzhou, Qionghai}</td>\n",
       "      <td>['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...</td>\n",
       "      <td>No</td>\n",
       "      <td>determine the locations of Cangzhou and Qionghai. Cangzhou is conf...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who conducts the draft in which Marc-Andre Fleury was drafted to t...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>{2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}</td>\n",
       "      <td>['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>identify the entity responsible for conducting the draft. The cont...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wings entered a new era, following the retirement of which Can...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>{Steve Yzerman, 2006–07 Detroit Red Wings season}</td>\n",
       "      <td>['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>identify the retired professional ice hockey player mentioned. The...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What river is near the Crichton Collegiate Church?</td>\n",
       "      <td>the River Tyne</td>\n",
       "      <td>{Crichton Collegiate Church, Crichton Castle}</td>\n",
       "      <td>[\"Crichton Collegiate Church | Crichton Collegiate Church is situa...</td>\n",
       "      <td>River Tyne</td>\n",
       "      <td>identify the river associated with the Crichton Collegiate Church....</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...</td>\n",
       "      <td>King Alfred the Great</td>\n",
       "      <td>{Æthelweard (son of Alfred), Ealhswith}</td>\n",
       "      <td>[\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...</td>\n",
       "      <td>Alfred the Great</td>\n",
       "      <td>identify the king who was the father of Æthelweard. From the conte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0         Are both Cangzhou and Qionghai in the Hebei province of China?   \n",
       "1  Who conducts the draft in which Marc-Andre Fleury was drafted to t...   \n",
       "2  The Wings entered a new era, following the retirement of which Can...   \n",
       "3                     What river is near the Crichton Collegiate Church?   \n",
       "4  In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...   \n",
       "\n",
       "           example_answer  \\\n",
       "0                      no   \n",
       "1  National Hockey League   \n",
       "2           Steve Yzerman   \n",
       "3          the River Tyne   \n",
       "4   King Alfred the Great   \n",
       "\n",
       "                                                      gold_titles  \\\n",
       "0                                            {Cangzhou, Qionghai}   \n",
       "1  {2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}   \n",
       "2               {Steve Yzerman, 2006–07 Detroit Red Wings season}   \n",
       "3                   {Crichton Collegiate Church, Crichton Castle}   \n",
       "4                         {Æthelweard (son of Alfred), Ealhswith}   \n",
       "\n",
       "                                                                 context  \\\n",
       "0  ['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...   \n",
       "1  ['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...   \n",
       "2  ['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...   \n",
       "3  [\"Crichton Collegiate Church | Crichton Collegiate Church is situa...   \n",
       "4  [\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...   \n",
       "\n",
       "              pred_answer  \\\n",
       "0                      No   \n",
       "1  National Hockey League   \n",
       "2           Steve Yzerman   \n",
       "3              River Tyne   \n",
       "4        Alfred the Great   \n",
       "\n",
       "                                                               rationale  \\\n",
       "0  determine the locations of Cangzhou and Qionghai. Cangzhou is conf...   \n",
       "1  identify the entity responsible for conducting the draft. The cont...   \n",
       "2  identify the retired professional ice hockey player mentioned. The...   \n",
       "3  identify the river associated with the Crichton Collegiate Church....   \n",
       "4  identify the king who was the father of Æthelweard. From the conte...   \n",
       "\n",
       "  answer_exact_match  \n",
       "0          ✔️ [True]  \n",
       "1          ✔️ [True]  \n",
       "2          ✔️ [True]  \n",
       "3          ✔️ [True]  \n",
       "4                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = LabeledFewShot(k=3)\n",
    "optimized_program = optimizer.compile(baseline, trainset=train_set)\n",
    "optimized_program.save(\"compiled_programs/LabeledFewShot_program.json\")\n",
    "\n",
    "evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Optimizers - Automatic Instruction Optimization\n",
    "\n",
    "These optimizers produce optimal instructions for the prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIPROv2\n",
    "\n",
    "Generates instructions and few-shot examples in each step. The instruction generation is data-aware and demonstration-aware. Uses Bayesian Optimization to effectively search over the space of generation instructions/demonstrations across your modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<center><img src=\"assets/mipro-schema.png\" width=\"400\"></center>"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 7\n",
      "minibatch: True\n",
      "num_candidates: 7\n",
      "valset size: 100\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001B[93m\u001B[1mProjected Language Model (LM) Calls\u001B[0m\n",
      "\n",
      "Based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001B[93m- Prompt Generation: \u001B[94m\u001B[1m10\u001B[0m\u001B[93m data summarizer calls + \u001B[94m\u001B[1m7\u001B[0m\u001B[93m * \u001B[94m\u001B[1m1\u001B[0m\u001B[93m lm calls in program + (\u001B[94m\u001B[1m2\u001B[0m\u001B[93m) lm calls in program-aware proposer = \u001B[94m\u001B[1m19\u001B[0m\u001B[93m prompt model calls\u001B[0m\n",
      "\u001B[93m- Program Evaluation: \u001B[94m\u001B[1m25\u001B[0m\u001B[93m examples in minibatch * \u001B[94m\u001B[1m7\u001B[0m\u001B[93m batches + \u001B[94m\u001B[1m100\u001B[0m\u001B[93m examples in val set * \u001B[94m\u001B[1m1\u001B[0m\u001B[93m full evals = \u001B[94m\u001B[1m275\u001B[0m\u001B[93m LM Program calls\u001B[0m\n",
      "\n",
      "\u001B[93m\u001B[1mEstimated Cost Calculation:\u001B[0m\n",
      "\n",
      "\u001B[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of program calls * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001B[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001B[93m- Reducing the number of trials (`num_trials`), the size of the valset, or the number of LM calls in your program.\u001B[0m\n",
      "\u001B[93m- Using a cheaper task model to optimize the prompt.\u001B[0m\n",
      "\u001B[93m- Setting `minibatch=True` if you haven't already.\u001B[0m\n",
      "\n",
      "To proceed with the execution of this program, please confirm by typing \u001B[94m'y'\u001B[0m for yes or \u001B[94m'n'\u001B[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001B[93m`requires_permission_to_run`\u001B[0m flag to \u001B[93m`False`\u001B[0m when calling compile.\n",
      "\n",
      "\u001B[93mAwaiting your input...\u001B[0m\n",
      "\n",
      "Do you wish to continue? (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used for informing instruction proposal.\n",
      "\n",
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=7 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/7\n",
      "Bootstrapping set 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17%|███████████████████████████████▋                                                                                                                                                              | 5/30 [00:00<00:00, 304.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17%|███████████████████████████████▋                                                                                                                                                              | 5/30 [00:00<00:00, 319.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 3%|██████▎                                                                                                                                                                                       | 1/30 [00:00<00:00, 180.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17%|███████████████████████████████▋                                                                                                                                                              | 5/30 [00:00<00:00, 297.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20%|██████████████████████████████████████                                                                                                                                                        | 6/30 [00:00<00:00, 277.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2024/12/09 13:50:22 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "SOURCE CODE: StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "DATA SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories.\n",
      "\n",
      "Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: ```plaintext\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: ```plaintext StringSignature(context, question -> rationale, answer instructions='Answer questions with short factoid answers.' context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'}) question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'}) rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'}) answer = Field(annotation\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S): \n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m Provide concise and accurate answers to questions based on the given context. Ensure that your responses include a brief rationale explaining your reasoning process, and keep the answers between 1 to 5 words, focusing on key facts related to notable individuals, events, or comparisons across various domains such as music, film, and history.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide concise and accurate answers to questions based on the given context. Ensure that your responses include a brief rationale explaining your reasoning process, and keep the answers between 1 to 5 words, focusing on key facts related to notable individuals, events, or comparisons across various domains such as music, film, and history.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve tasks related to answering factual questions based on provided contextual information. Specifically, it aims to determine the correct answer to a question by retrieving relevant facts from a set of given contexts and reasoning through the information to arrive at a conclusion.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. **Input Fields**: The program defines several fields:\n",
      "   - `context`: A list of strings containing relevant facts about individuals or topics.\n",
      "   - `question`: A specific question posed about the information contained in the context.\n",
      "   - `rationale`: A field for the program to express its reasoning process step by step.\n",
      "   - `answer`: The final output, which is a concise factoid answer to the question.\n",
      "\n",
      "2. **Retrieval\n",
      "task_demos Context: ['Aleksandr Danilovich Aleksandrov | Aleksandr Danilovich Aleksandrov (Russian: Алекса́ндр Дани́лович Алекса́ндров , alternative transliterations: \"Alexandr\" or \"Alexander\" (first name), and \"Alexandrov\" (last name)) (August 4, 1912 – July 27, 1999), was a Soviet/Russian mathematician, physicist, philosopher and mountaineer.', 'Aleksandr Pavlovich Aleksandrov | Aleksandr Pavlovich Aleksandrov (Russian: Александр Павлович Александров ; born February 20, 1943) is a former Soviet cosmonaut and twice Hero of the Soviet Union (November 23, 1983 and December 29, 1987).', 'Aleksandr Piskaryov | Aleksandr Mikhaiylovich Piskaryov (Russian: Александр Михайлович Пискарёв ) (born November 18, 1949) is a Russian football player and manager.']\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their ages. Aleksandr Danilovich Aleksandrov was born on August 4, 1912, while Anatoly Fomenko was born on March 12, 1932. Since 1912 is earlier than 1932, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve tasks related to answering factual questions based on provided contextual information. Specifically, it aims to determine the correct answer to a question by retrieving relevant facts from a set of given contexts and reasoning through the information to arrive at a conclusion. Here's how it works: 1. **Input Fields**: The program defines several fields: - `context`: A list of strings containing relevant facts about individuals or topics. - `question`: A specific question posed about the information contained in the context. - `rationale`: A field for the program to express its reasoning process step by step. - `answer`: The final output, which is a concise factoid answer to the question. 2. **Retrieval\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['Aleksandr Danilovich Aleksandrov | Aleksandr Danilovich Aleksandrov (Russian: Алекса́ндр Дани́лович Алекса́ндров , alternative transliterations: \"Alexandr\" or \"Alexander\" (first name), and \"Alexandrov\" (last name)) (August 4, 1912 – July 27, 1999), was a Soviet/Russian mathematician, physicist, philosopher and mountaineer.', 'Aleksandr Pavlovich Aleksandrov | Aleksandr Pavlovich Aleksandrov (Russian: Александр Павлович Александров ; born February 20, 1943) is a former Soviet cosmonaut and twice Hero of the Soviet Union (November 23, 1983 and December 29, 1987).', 'Aleksandr Piskaryov | Aleksandr Mikhaiylovich Piskaryov (Russian: Александр Михайлович Пискарёв ) (born November 18, 1949) is a Russian football player and manager.']\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Reasoning: Let's think step by step in order to determine their ages. Aleksandr Danilovich Aleksandrov was born on August 4, 1912, while Anatoly Fomenko was born on March 12, 1932. Since 1912 is earlier than 1932, Aleksandr Danilovich Aleksandrov is older.\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m Propose a detailed instruction that guides the Language Model to effectively analyze the provided context and answer comparative questions about notable figures or events, ensuring clarity in reasoning and conciseness in the final answer. Include a reminder to check the birthdates or relevant details to establish accurate comparisons.\n",
      "\n",
      "**PROPOSED INSTRUCTION:** \n",
      "\n",
      "\"Given the provided context containing facts about notable individuals or events, analyze the information carefully to answer the specific comparative question. Ensure that your reasoning is clear and logical by outlining the relevant details step by step. Focus on key dates or significant achievements to establish comparisons accurately. Finally, provide a concise factoid answer that directly addresses the question posed.\"\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose a detailed instruction that guides the Language Model to effectively analyze the provided context and answer comparative questions about notable figures or events, ensuring clarity in reasoning and conciseness in the final answer. Include a reminder to check the birthdates or relevant details to establish accurate comparisons.\n",
      "\n",
      "**PROPOSED INSTRUCTION:** \n",
      "\n",
      "\"Given the provided context containing facts about notable individuals or events, analyze the information carefully to answer the specific comparative question. Ensure that your reasoning is clear and logical by outlining the relevant details step by step. Focus on key dates or significant achievements to establish comparisons accurately. Finally, provide a concise factoid answer that directly addresses the question posed.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based questions by leveraging information retrieved from a provided context. It operates within a framework that combines information retrieval and language generation to produce concise answers based on the context provided.\n",
      "\n",
      "The program works as follows:\n",
      "\n",
      "1. **Input Fields**: It takes in a context (which includes relevant facts), a question, and outputs a rationale and an answer. The context is expected to contain factual information that can help answer the question.\n",
      "\n",
      "2. **Retrieval Module**: The `BaselineRAG` class initializes a retrieval system that fetches a specified number of relevant passages (in this case, three) based on the question. This is done using the `dspy.Retrieve` method.\n",
      "\n",
      "3. **Answer Generation\n",
      "task_demos Context: ['Who Put the Bomp | Who Put The Bomp was a rock music fanzine edited and published by Greg Shaw from 1970 to 1979. Its name came from the hit 1961 doo-wop song by Barry Mann, \"Who Put the Bomp\". Later, the name was shortened to \"Bomp!\"', 'Bompiani | Bompiani is an Italian publishing house based in Milan, Italy. It was founded in 1929 by Valentino Bompiani.', \"What Color is Your Parachute? | What Color is Your Parachute? by Richard Nelson Bolles is a book for job-seekers that has been in print since 1970 and has been revised every year since 1975, sometimes substantially. Bolles initially self-published the book (December 1, 1970), but it has been commercially published since November 1972 by Ten Speed Press in Berkeley, California. As of September 28, 2010, the book is available in 22 languages, it is used in 26 countries around the world, and over ten million copies have been sold worldwide. It is one of the most highly regarded career advice books in print. In the latest edition of the book, the author writes about how to adapt one's job search to the Web 2.0 age.\"]\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication is more recent. \"Who Put the Bomp\" was published from 1970 to 1979, while \"Self\" magazine was first published in 1979 and continues to be released. Thus, \"Self\" is more recent.\n",
      "Answer: Self\n",
      "Context: ['The Victorians | The Victorians - Their Story In Pictures is a 2009 British documentary series which focuses on Victorian art and culture. The four-part series is written and presented by Jeremy Paxman and debuted on BBC One at 9:00pm on Sunday 15 February 2009.', 'Victorian (comics) | The Victorian is a 25-issue comic book series published by Penny-Farthing Press and starting in 1999. The brainchild of creator Trainor Houghton, the series included a number of notable script writers and illustrators, including Len Wein, Glen Orbik and Howard Chaykin.', 'The Great Victorian Collection | The Great Victorian Collection, published in 1975, is a novel by Northern Irish-Canadian writer Brian Moore. Set in Carmel, California, it tells the story of a man who dreams that the empty parking lot he can see from his hotel window has been transformed by the arrival of a collection of priceless Victoriana on display in a vast open-air market. When he awakes he finds that he can no longer distinguish the dream from reality.']\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Reasoning: Let's think step by step in order to determine the birth year of the author. The documentary series \"The Victorians\" is written by Jeremy Paxman. Jeremy Paxman was born in 1950.\n",
      "Answer: 1950\n",
      "Context: ['Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.', \"Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.\", 'Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine\\'s Hall of Fame and \"Tae Kwon Do Times\" magazine\\'s Hall of Fame.']\n",
      "Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?\n",
      "Reasoning: Let's think step by step in order to identify the correct magazine. The context states that \"Tae Kwon Do Times\" published articles by Scott Shaw, while there is no mention of \"Southwest Art.\" Therefore, we can conclude that Scott Shaw's articles appear in \"Tae Kwon Do Times.\"\n",
      "Answer: Tae Kwon Do Times\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based questions by leveraging information retrieved from a provided context. It operates within a framework that combines information retrieval and language generation to produce concise answers based on the context provided. The program works as follows: 1. **Input Fields**: It takes in a context (which includes relevant facts), a question, and outputs a rationale and an answer. The context is expected to contain factual information that can help answer the question. 2. **Retrieval Module**: The `BaselineRAG` class initializes a retrieval system that fetches a specified number of relevant passages (in this case, three) based on the question. This is done using the `dspy.Retrieve` method. 3. **Answer Generation\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['Who Put the Bomp | Who Put The Bomp was a rock music fanzine edited and published by Greg Shaw from 1970 to 1979. Its name came from the hit 1961 doo-wop song by Barry Mann, \"Who Put the Bomp\". Later, the name was shortened to \"Bomp!\"', 'Bompiani | Bompiani is an Italian publishing house based in Milan, Italy. It was founded in 1929 by Valentino Bompiani.', \"What Color is Your Parachute? | What Color is Your Parachute? by Richard Nelson Bolles is a book for job-seekers that has been in print since 1970 and has been revised every year since 1975, sometimes substantially. Bolles initially self-published the book (December 1, 1970), but it has been commercially published since November 1972 by Ten Speed Press in Berkeley, California. As of September 28, 2010, the book is available in 22 languages, it is used in 26 countries around the world, and over ten million copies have been sold worldwide. It is one of the most highly regarded career advice books in print. In the latest edition of the book, the author writes about how to adapt one's job search to the Web 2.0 age.\"]\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Reasoning: Let's think step by step in order to determine which publication is more recent. \"Who Put the Bomp\" was published from 1970 to 1979, while \"Self\" magazine was first published in 1979 and continues to be released. Thus, \"Self\" is more recent.\n",
      "Answer: Self\n",
      "Context: ['The Victorians | The Victorians - Their Story In Pictures is a 2009 British documentary series which focuses on Victorian art and culture. The four-part series is written and presented by Jeremy Paxman and debuted on BBC One at 9:00pm on Sunday 15 February 2009.', 'Victorian (comics) | The Victorian is a 25-issue comic book series published by Penny-Farthing Press and starting in 1999. The brainchild of creator Trainor Houghton, the series included a number of notable script writers and illustrators, including Len Wein, Glen Orbik and Howard Chaykin.', 'The Great Victorian Collection | The Great Victorian Collection, published in 1975, is a novel by Northern Irish-Canadian writer Brian Moore. Set in Carmel, California, it tells the story of a man who dreams that the empty parking lot he can see from his hotel window has been transformed by the arrival of a collection of priceless Victoriana on display in a vast open-air market. When he awakes he finds that he can no longer distinguish the dream from reality.']\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Reasoning: Let's think step by step in order to determine the birth year of the author. The documentary series \"The Victorians\" is written by Jeremy Paxman. Jeremy Paxman was born in 1950.\n",
      "Answer: 1950\n",
      "Context: ['Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.', \"Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.\", 'Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine\\'s Hall of Fame and \"Tae Kwon Do Times\" magazine\\'s Hall of Fame.']\n",
      "Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?\n",
      "Reasoning: Let's think step by step in order to identify the correct magazine. The context states that \"Tae Kwon Do Times\" published articles by Scott Shaw, while there is no mention of \"Southwest Art.\" Therefore, we can conclude that Scott Shaw's articles appear in \"Tae Kwon Do Times.\"\n",
      "Answer: Tae Kwon Do Times\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m Provide concise, fact-based answers to the following questions, using the given context to support your reasoning. Please ensure that your responses are clear and directly address the question asked.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide concise, fact-based answers to the following questions, using the given context to support your reasoning. Please ensure that your responses are clear and directly address the question asked.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve tasks related to answering comparative questions about music bands based on provided contextual information. It retrieves relevant passages of text that contain information about the bands and then generates a concise answer along with a rationale explaining the reasoning behind that answer.\n",
      "\n",
      "The process begins with the program receiving a context containing relevant facts about different bands and a specific question regarding those bands. It utilizes a retrieval mechanism to gather pertinent passages from the context based on the question. Once the relevant information is gathered, the program employs a language model to generate an answer and a rationale. The rationale explains the reasoning process step by step, allowing for transparency in how the answer was derived.\n",
      "\n",
      "In the provided example, the context includes information about \"The Last Shadow Puppets\n",
      "task_demos Context: ['The Last Shadow Puppets | The Last Shadow Puppets are an English supergroup consisting of Alex Turner (Arctic Monkeys), Miles Kane (The Rascals, solo artist), James Ford (Simian, Simian Mobile Disco, music producer), and Zach Dawes (Mini Mansions). They are joined live by Loren Humphrey (Guards, music producer, session musician) and Tyler Parkford (Mini Mansions). The band released their debut album \"The Age of the Understatement\" in 2008. Following a lengthy hiatus, they returned, releasing second album \"Everything You\\'ve Come to Expect\" in 2016.', 'Juliette and the Licks | Juliette & The Licks is an American rock band led by actress and singer Juliette Lewis. Other band members have included guitarist Craig Fairbaugh and guitarist Emilio Cueto, bassist Jason Womack and drummer Ed Davis. Their popular songs include \"You\\'re Speaking My Language\" and \"Hot Kiss\". The band broke up in 2009. In 2015, Lewis announced the band would be reunited on July 23rd for a show in Los Angeles. The future of the band past this show was unknown until Juliette announced, via her Facebook account on Feb 1st 2016, that the band will play a gig in London\\'s Heaven on May 4th 2016. In June of 2016, Juliette Lewis announced a solo tour leaving the future of The Licks undetermined.', 'The Age of the Understatement | The Age of the Understatement is the debut album by The Last Shadow Puppets, featuring Alex Turner of Arctic Monkeys, Miles Kane of The Rascals and James Ford of Simian Mobile Disco. It was released on 21 April 2008 in the UK, following the release of their eponymous single in the previous week. It entered the UK Album Chart at No. 1 on 27 April 2008. The album was nominated for the 2008 Mercury Music Prize.']\n",
      "Question: Which band had a longer hiatus, Juliette and the Licks or The Last Shadow Puppets?\n",
      "Reasoning: Let's think step by step in order to compare the durations of their hiatuses. The Last Shadow Puppets took a lengthy hiatus before releasing their second album in 2016. Juliette and the Licks broke up in 2009 and reunited for a show in 2015, but their future was uncertain afterward. Thus, we will determine the time between their last activity and their next significant event.\n",
      "Answer: The Last Shadow Puppets\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve tasks related to answering comparative questions about music bands based on provided contextual information. It retrieves relevant passages of text that contain information about the bands and then generates a concise answer along with a rationale explaining the reasoning behind that answer. The process begins with the program receiving a context containing relevant facts about different bands and a specific question regarding those bands. It utilizes a retrieval mechanism to gather pertinent passages from the context based on the question. Once the relevant information is gathered, the program employs a language model to generate an answer and a rationale. The rationale explains the reasoning process step by step, allowing for transparency in how the answer was derived. In the provided example, the context includes information about \"The Last Shadow Puppets\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['The Last Shadow Puppets | The Last Shadow Puppets are an English supergroup consisting of Alex Turner (Arctic Monkeys), Miles Kane (The Rascals, solo artist), James Ford (Simian, Simian Mobile Disco, music producer), and Zach Dawes (Mini Mansions). They are joined live by Loren Humphrey (Guards, music producer, session musician) and Tyler Parkford (Mini Mansions). The band released their debut album \"The Age of the Understatement\" in 2008. Following a lengthy hiatus, they returned, releasing second album \"Everything You\\'ve Come to Expect\" in 2016.', 'Juliette and the Licks | Juliette & The Licks is an American rock band led by actress and singer Juliette Lewis. Other band members have included guitarist Craig Fairbaugh and guitarist Emilio Cueto, bassist Jason Womack and drummer Ed Davis. Their popular songs include \"You\\'re Speaking My Language\" and \"Hot Kiss\". The band broke up in 2009. In 2015, Lewis announced the band would be reunited on July 23rd for a show in Los Angeles. The future of the band past this show was unknown until Juliette announced, via her Facebook account on Feb 1st 2016, that the band will play a gig in London\\'s Heaven on May 4th 2016. In June of 2016, Juliette Lewis announced a solo tour leaving the future of The Licks undetermined.', 'The Age of the Understatement | The Age of the Understatement is the debut album by The Last Shadow Puppets, featuring Alex Turner of Arctic Monkeys, Miles Kane of The Rascals and James Ford of Simian Mobile Disco. It was released on 21 April 2008 in the UK, following the release of their eponymous single in the previous week. It entered the UK Album Chart at No. 1 on 27 April 2008. The album was nominated for the 2008 Mercury Music Prize.']\n",
      "Question: Which band had a longer hiatus, Juliette and the Licks or The Last Shadow Puppets?\n",
      "Reasoning: Let's think step by step in order to compare the durations of their hiatuses. The Last Shadow Puppets took a lengthy hiatus before releasing their second album in 2016. Juliette and the Licks broke up in 2009 and reunited for a show in 2015, but their future was uncertain afterward. Thus, we will determine the time between their last activity and their next significant event.\n",
      "Answer: The Last Shadow Puppets\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m Provide a detailed analysis of the context provided and answer the question by comparing the relevant information about the two bands. Ensure to include a rationale that explains the reasoning process step by step, highlighting key dates and events that contribute to the comparison. Aim for a concise answer that directly addresses the question while maintaining clarity and transparency in your rationale.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide a detailed analysis of the context provided and answer the question by comparing the relevant information about the two bands. Ensure to include a rationale that explains the reasoning process step by step, highlighting key dates and events that contribute to the comparison. Aim for a concise answer that directly addresses the question while maintaining clarity and transparency in your rationale.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: persona\n",
      "PROGRAM DESCRIPTION: The program is designed to answer specific fact-based questions using contextual information retrieved from a set of relevant passages. It utilizes a pipeline that involves retrieving information, reasoning through that information, and generating concise answers.\n",
      "\n",
      "1. **Task**: The primary task of the program is to answer factoid questions based on provided context. It is particularly focused on extracting specific information (like names, organizations, or terms) from a given set of textual data.\n",
      "\n",
      "2. **How it Works**:\n",
      "   - **Input Fields**: The program takes in a context (a list of relevant passages), a question, and outputs a rationale and an answer.\n",
      "   - **Retrieval Module**: It first retrieves a specified number of relevant passages (defined by `num_pass\n",
      "task_demos Context: ['Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC\\'s \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly\\'s Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.', 'Judi Dench | Dame Judith Olivia \"Judi\" Dench, {\\'1\\': \", \\'2\\': \", \\'3\\': \", \\'4\\': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare\\'s plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.']\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Reasoning: Let's think step by step in order to identify the actress who fits both criteria. The context mentions Kerry Condon as the youngest actress to play Ophelia in a Royal Shakespeare Company production and also notes her work in various films.\n",
      "Answer: Kerry Condon\n",
      "Context: ['The Sword in the Stone (film) | The Sword in the Stone is a 1963 American animated musical fantasy comedy film produced by Walt Disney and released by Buena Vista Distribution. The 18th Disney animated feature film, it was the final Disney animated film to be released before Walt Disney\\'s death. The songs in the film were written and composed by the Sherman Brothers, who later wrote music for other Disney films like \"Mary Poppins\" (1964), \"The Jungle Book\" (1967), \"The Aristocats\" (1970), and \"Bedknobs and Broomsticks\" (1971).', 'A Symposium on Popular Songs | A Symposium on Popular Songs is a special cartoon featurette made by Walt Disney Productions in 1962. It features songs written by the Sherman Brothers with music arrangements by Tutti Camarata. The Shermans also co-wrote the screenplay but are not credited for this. Host Ludwig Von Drake invites his audience into his mansion where he tells all about popular music through the years, introducing several songs illustrated with stop-motion photography. The film was nominated for an Academy Award for Best Animated Short Film. It was released on DVD in 2005 as part of the Walt Disney Treasures set \"Disney Rarities\".', 'Winnie the Pooh and the Blustery Day | Winnie the Pooh and the Blustery Day is a 1968 animated featurette based on the third, fifth, ninth, and tenth chapters from \"Winnie-the-Pooh\" and the second, eighth, and ninth chapters from \"The House at Pooh Corner\" by A. A. Milne. The featurette was produced by Walt Disney Productions and released by Buena Vista Distribution Company on December 20, 1968 as a double feature with \"The Horse in the Gray Flannel Suit\". This was the second of the studio\\'s Winnie the Pooh shorts. It was later added as a segment to the 1977 film \"The Many Adventures of Winnie the Pooh\". The music was written by Richard M. Sherman and Robert B. Sherman. It was notable for being the last animated short produced by Walt Disney, who died during its production.']\n",
      "Question: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?\n",
      "Reasoning: Let's think step by step in order to identify the company that distributed the film. The context mentions that \"Winnie the Pooh and the Blustery Day\" was released by Buena Vista Distribution Company and that it was later added to \"The Many Adventures of Winnie the Pooh,\" a 1977 film. Therefore, we conclude that the same company distributed the 1977 film.\n",
      "Answer: Buena Vista Distribution\n",
      "Context: ['Eric Davis (baseball) | Eric Keith Davis (born May 29, 1962) is a former center fielder for several Major League Baseball teams. Davis was 21 years old when he broke into the big leagues on May 19, 1984 with the Cincinnati Reds, the team for which he is most remembered. Blessed with a rare combination of excellent foot speed and bat speed, Davis became the first major league player to hit at least 30 home runs and steal at least 50 bases in the same season in 1987.', \"Willie Davis (baseball) | William Henry Davis, Jr. (April 15, 1940 – March 9, 2010) was a center fielder in Major League Baseball who played most of his career for the Los Angeles Dodgers. At the end of his career he ranked seventh in major league history in putouts (5449) and total chances (5719) in the outfield, and third in games in center field (2237). He was ninth in National League history in total outfield games (2274), and won Gold Glove Awards from 1971 to 1973. He had 13 seasons of 20 or more stolen bases, led the NL in triples twice, and retired with the fourth most triples (138) by any major leaguer since 1945. He holds Los Angeles club records (1958–present) for career hits (2091), runs (1004), triples (110), at bats (7495), total bases (3094) and extra base hits (585). His 31-game hitting streak in 1969 remains the longest by a Dodger. At one point during the streak, when the team was playing at home, the big message board at Dodger Stadium quoted a message from a telegram sent to Davis and the team from Zack Wheat, the team's former record holder, at his home in Missouri.\", '1992 Los Angeles Dodgers season | The 1992 Los Angeles Dodgers season was a poor one for the team as it finished last in the Western Division of the National League with a record of 63 wins and 99 losses. Despite boasting what was nicknamed the \"Outfield of Dreams\", being manned by Eric Davis, Brett Butler, and Darryl Strawberry, injuries to key players and slumps from others contributed to the franchise\\'s worst season since moving to Los Angeles. Additionally, the Dodgers cancelled four home games during the season due to the L.A. Riots. Despite the poor finish, the Dodgers had some hope for the future as first baseman Eric Karros won the National League Rookie of the Year Award, the first of five consecutive Dodger players to do so. The 1992 season also saw the Dodgers drop television station KTTV Ch.11 as their chief broadcaster of Dodger baseball, ending a 34 year-35 consecutive season association with that station. Additionally, it was the first time the Dodgers lost 90 games in a season since 1944.']\n",
      "Question: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers? \n",
      "Reasoning: Let's think step by step in order to identify the qualities of Eric Davis and how they contributed to the overall performance of the Dodgers' outfield during his time. We know that his speed and batting ability would enhance the outfield's defensive capabilities and offensive production.\n",
      "Answer: \"Outfield of Dreams\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program is designed to answer specific fact-based questions using contextual information retrieved from a set of relevant passages. It utilizes a pipeline that involves retrieving information, reasoning through that information, and generating concise answers. 1. **Task**: The primary task of the program is to answer factoid questions based on provided context. It is particularly focused on extracting specific information (like names, organizations, or terms) from a given set of textual data. 2. **How it Works**: - **Input Fields**: The program takes in a context (a list of relevant passages), a question, and outputs a rationale and an answer. - **Retrieval Module**: It first retrieves a specified number of relevant passages (defined by `num_pass\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC\\'s \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly\\'s Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.', 'Judi Dench | Dame Judith Olivia \"Judi\" Dench, {\\'1\\': \", \\'2\\': \", \\'3\\': \", \\'4\\': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare\\'s plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.']\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Reasoning: Let's think step by step in order to identify the actress who fits both criteria. The context mentions Kerry Condon as the youngest actress to play Ophelia in a Royal Shakespeare Company production and also notes her work in various films.\n",
      "Answer: Kerry Condon\n",
      "Context: ['The Sword in the Stone (film) | The Sword in the Stone is a 1963 American animated musical fantasy comedy film produced by Walt Disney and released by Buena Vista Distribution. The 18th Disney animated feature film, it was the final Disney animated film to be released before Walt Disney\\'s death. The songs in the film were written and composed by the Sherman Brothers, who later wrote music for other Disney films like \"Mary Poppins\" (1964), \"The Jungle Book\" (1967), \"The Aristocats\" (1970), and \"Bedknobs and Broomsticks\" (1971).', 'A Symposium on Popular Songs | A Symposium on Popular Songs is a special cartoon featurette made by Walt Disney Productions in 1962. It features songs written by the Sherman Brothers with music arrangements by Tutti Camarata. The Shermans also co-wrote the screenplay but are not credited for this. Host Ludwig Von Drake invites his audience into his mansion where he tells all about popular music through the years, introducing several songs illustrated with stop-motion photography. The film was nominated for an Academy Award for Best Animated Short Film. It was released on DVD in 2005 as part of the Walt Disney Treasures set \"Disney Rarities\".', 'Winnie the Pooh and the Blustery Day | Winnie the Pooh and the Blustery Day is a 1968 animated featurette based on the third, fifth, ninth, and tenth chapters from \"Winnie-the-Pooh\" and the second, eighth, and ninth chapters from \"The House at Pooh Corner\" by A. A. Milne. The featurette was produced by Walt Disney Productions and released by Buena Vista Distribution Company on December 20, 1968 as a double feature with \"The Horse in the Gray Flannel Suit\". This was the second of the studio\\'s Winnie the Pooh shorts. It was later added as a segment to the 1977 film \"The Many Adventures of Winnie the Pooh\". The music was written by Richard M. Sherman and Robert B. Sherman. It was notable for being the last animated short produced by Walt Disney, who died during its production.']\n",
      "Question: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?\n",
      "Reasoning: Let's think step by step in order to identify the company that distributed the film. The context mentions that \"Winnie the Pooh and the Blustery Day\" was released by Buena Vista Distribution Company and that it was later added to \"The Many Adventures of Winnie the Pooh,\" a 1977 film. Therefore, we conclude that the same company distributed the 1977 film.\n",
      "Answer: Buena Vista Distribution\n",
      "Context: ['Eric Davis (baseball) | Eric Keith Davis (born May 29, 1962) is a former center fielder for several Major League Baseball teams. Davis was 21 years old when he broke into the big leagues on May 19, 1984 with the Cincinnati Reds, the team for which he is most remembered. Blessed with a rare combination of excellent foot speed and bat speed, Davis became the first major league player to hit at least 30 home runs and steal at least 50 bases in the same season in 1987.', \"Willie Davis (baseball) | William Henry Davis, Jr. (April 15, 1940 – March 9, 2010) was a center fielder in Major League Baseball who played most of his career for the Los Angeles Dodgers. At the end of his career he ranked seventh in major league history in putouts (5449) and total chances (5719) in the outfield, and third in games in center field (2237). He was ninth in National League history in total outfield games (2274), and won Gold Glove Awards from 1971 to 1973. He had 13 seasons of 20 or more stolen bases, led the NL in triples twice, and retired with the fourth most triples (138) by any major leaguer since 1945. He holds Los Angeles club records (1958–present) for career hits (2091), runs (1004), triples (110), at bats (7495), total bases (3094) and extra base hits (585). His 31-game hitting streak in 1969 remains the longest by a Dodger. At one point during the streak, when the team was playing at home, the big message board at Dodger Stadium quoted a message from a telegram sent to Davis and the team from Zack Wheat, the team's former record holder, at his home in Missouri.\", '1992 Los Angeles Dodgers season | The 1992 Los Angeles Dodgers season was a poor one for the team as it finished last in the Western Division of the National League with a record of 63 wins and 99 losses. Despite boasting what was nicknamed the \"Outfield of Dreams\", being manned by Eric Davis, Brett Butler, and Darryl Strawberry, injuries to key players and slumps from others contributed to the franchise\\'s worst season since moving to Los Angeles. Additionally, the Dodgers cancelled four home games during the season due to the L.A. Riots. Despite the poor finish, the Dodgers had some hope for the future as first baseman Eric Karros won the National League Rookie of the Year Award, the first of five consecutive Dodger players to do so. The 1992 season also saw the Dodgers drop television station KTTV Ch.11 as their chief broadcaster of Dodger baseball, ending a 34 year-35 consecutive season association with that station. Additionally, it was the first time the Dodgers lost 90 games in a season since 1944.']\n",
      "Question: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers? \n",
      "Reasoning: Let's think step by step in order to identify the qualities of Eric Davis and how they contributed to the overall performance of the Dodgers' outfield during his time. We know that his speed and batting ability would enhance the outfield's defensive capabilities and offensive production.\n",
      "Answer: \"Outfield of Dreams\"\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Include a persona that is relevant to the task in the instruction (ie. \"You are a ...\")\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m You are a knowledgeable historian and trivia expert. Answer the following questions with concise factoid answers based on the provided context, ensuring to highlight key details and connections relevant to the inquiry.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a knowledgeable historian and trivia expert. Answer the following questions with concise factoid answers based on the provided context, ensuring to highlight key details and connections relevant to the inquiry.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: persona\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based question-answering tasks using a language model. Specifically, it retrieves relevant context from a set of documents or passages and generates concise answers based on that context.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. **Input Parameters**: The program takes in a context (a set of passages containing relevant information) and a question that needs to be answered. The context is expected to provide factual information that can help in answering the question.\n",
      "\n",
      "2. **Retrieval Module**: The `BaselineRAG` class initializes a retrieval system that fetches a specified number of context passages related to the question posed. This is done through the `self.retrieve` function, which looks for the most relevant documents.\n",
      "\n",
      "3. **Answer\n",
      "task_demos Context: ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.']\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Reasoning: Let's think step by step in order to identify the actress known for her debut in \"Kids\" and her involvement in Voto Latino. We know from the context that Rosario Dawson made her film debut in \"Kids\" and is also mentioned as a political activist. Therefore, she is likely the co-founder of Voto Latino.\n",
      "Answer: Rosario Dawson\n",
      "Context: ['Everything Has Changed | \"Everything Has Changed\" is a song written and performed by American singer-songwriter Taylor Swift and English singer-songwriter Ed Sheeran, taken from Swift\\'s fourth studio album, \"Red\" (2012). Produced by Butch Walker, the track was released as the sixth single from the album on July 16, 2013. \"Everything Has Changed\" is a guitar ballad combining folk and pop genres about \"wanting to get to know a new lover better\".', 'Changes (A Cursive Memory album) | Changes is an album by A Cursive Memory. It was released February 19, 2008 by Vagrant Records. The singles from the album were \"Everything\" and \"Perfect Company\". The song \"Everything\" was included in the game .', 'Everything Must Change | Everything Must Change is the debut album by singer Randy Crawford released in 1976 on the Warner Bros. label. It was recorded and mixed at Hollywood Sound Recorders except \"I\\'m Easy\" and \"I\\'ve Never Been To Me\", which, along with all horns and strings, were recorded at The Hit Factory, New York City, and engineered by Kevin Herron with assistant engineer Ted Spencer. In addition \"Everything Must Change\" and \"Gonna Give Lovin\\' A Try\" were recorded live at the World Jazz Association\\'s first recorded concert at the Shrine Auditorium in Los Angeles in November 1975.']\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Reasoning: Let's think step by step in order to identify the album and its record label. The song \"Everything Has Changed\" is from Taylor Swift's album \"Red,\" which is produced by Big Machine Records.\n",
      "Answer: Big Machine Records\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "TIP: A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based question-answering tasks using a language model. Specifically, it retrieves relevant context from a set of documents or passages and generates concise answers based on that context. Here's how it works: 1. **Input Parameters**: The program takes in a context (a set of passages containing relevant information) and a question that needs to be answered. The context is expected to provide factual information that can help in answering the question. 2. **Retrieval Module**: The `BaselineRAG` class initializes a retrieval system that fetches a specified number of context passages related to the question posed. This is done through the `self.retrieve` function, which looks for the most relevant documents. 3. **Answer\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.']\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Reasoning: Let's think step by step in order to identify the actress known for her debut in \"Kids\" and her involvement in Voto Latino. We know from the context that Rosario Dawson made her film debut in \"Kids\" and is also mentioned as a political activist. Therefore, she is likely the co-founder of Voto Latino.\n",
      "Answer: Rosario Dawson\n",
      "Context: ['Everything Has Changed | \"Everything Has Changed\" is a song written and performed by American singer-songwriter Taylor Swift and English singer-songwriter Ed Sheeran, taken from Swift\\'s fourth studio album, \"Red\" (2012). Produced by Butch Walker, the track was released as the sixth single from the album on July 16, 2013. \"Everything Has Changed\" is a guitar ballad combining folk and pop genres about \"wanting to get to know a new lover better\".', 'Changes (A Cursive Memory album) | Changes is an album by A Cursive Memory. It was released February 19, 2008 by Vagrant Records. The singles from the album were \"Everything\" and \"Perfect Company\". The song \"Everything\" was included in the game .', 'Everything Must Change | Everything Must Change is the debut album by singer Randy Crawford released in 1976 on the Warner Bros. label. It was recorded and mixed at Hollywood Sound Recorders except \"I\\'m Easy\" and \"I\\'ve Never Been To Me\", which, along with all horns and strings, were recorded at The Hit Factory, New York City, and engineered by Kevin Herron with assistant engineer Ted Spencer. In addition \"Everything Must Change\" and \"Gonna Give Lovin\\' A Try\" were recorded live at the World Jazz Association\\'s first recorded concert at the Shrine Auditorium in Los Angeles in November 1975.']\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Reasoning: Let's think step by step in order to identify the album and its record label. The song \"Everything Has Changed\" is from Taylor Swift's album \"Red,\" which is produced by Big Machine Records.\n",
      "Answer: Big Machine Records\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "TIP: Include a persona that is relevant to the task in the instruction (ie. \"You are a ...\")\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Answer questions with short factoid answers.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Propose a detailed instruction that guides the Language Model to effectively analyze the provided context and answer comparative questions about notable figures or events, ensuring clarity in reasoning and conciseness in the final answer. Include a reminder to check the birthdates or relevant details to establish accurate comparisons.\n",
      "\n",
      "**PROPOSED INSTRUCTION:** \n",
      "\n",
      "\"Given the provided context containing facts about notable individuals or events, analyze the information carefully to answer the specific comparative question. Ensure that your reasoning is clear and logical by outlining the relevant details step by step. Focus on key dates or significant achievements to establish comparisons accurately. Finally, provide a concise factoid answer that directly addresses the question posed.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Provide concise, fact-based answers to the following questions, using the given context to support your reasoning. Please ensure that your responses are clear and directly address the question asked.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Provide a detailed analysis of the context provided and answer the question by comparing the relevant information about the two bands. Ensure to include a rationale that explains the reasoning process step by step, highlighting key dates and events that contribute to the comparison. Aim for a concise answer that directly addresses the question while maintaining clarity and transparency in your rationale.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are a knowledgeable historian and trivia expert. Answer the following questions with concise factoid answers based on the provided context, ensuring to highlight key details and connections relevant to the inquiry.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: 6: Provide concise and accurate answers to fact-based questions by first analyzing the relevant context, then applying logical reasoning to derive the answer. Ensure that the response includes a brief rationale explaining the thought process behind the answer.\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based question-answering tasks by leveraging a retrieval-augmented generation (RAG) approach. It utilizes a context of relevant information to provide concise answers to specific questions while also generating a rationale for the answers based on logical reasoning.\n",
      "\n",
      "The program works as follows:\n",
      "\n",
      "1. **Context Retrieval**: When a question is posed, the program first retrieves a set of relevant passages (or context) that may contain information necessary to answer the question. This is done using a retrieval module that fetches a specified number of passages (in this case, three) based on the question.\n",
      "\n",
      "2. **Answer Generation**: After retrieving the context, the program employs a chain-of-thought reasoning mechanism to process the context\n",
      "task_demos Context: ['The Victorians | The Victorians - Their Story In Pictures is a 2009 British documentary series which focuses on Victorian art and culture. The four-part series is written and presented by Jeremy Paxman and debuted on BBC One at 9:00pm on Sunday 15 February 2009.', 'Victorian (comics) | The Victorian is a 25-issue comic book series published by Penny-Farthing Press and starting in 1999. The brainchild of creator Trainor Houghton, the series included a number of notable script writers and illustrators, including Len Wein, Glen Orbik and Howard Chaykin.', 'The Great Victorian Collection | The Great Victorian Collection, published in 1975, is a novel by Northern Irish-Canadian writer Brian Moore. Set in Carmel, California, it tells the story of a man who dreams that the empty parking lot he can see from his hotel window has been transformed by the arrival of a collection of priceless Victoriana on display in a vast open-air market. When he awakes he finds that he can no longer distinguish the dream from reality.']\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Reasoning: Let's think step by step in order to determine the birth year of the author. The documentary series \"The Victorians\" is written by Jeremy Paxman. Jeremy Paxman was born in 1950.\n",
      "Answer: 1950\n",
      "Context: ['Columbia Center | The Columbia Center, formerly named the Bank of America Tower and Columbia Seafirst Center, is a skyscraper in downtown Seattle, Washington. The 76-story structure is the tallest building in Seattle and the state of Washington, reaching a height of 937 ft . At the time of its completion, the Columbia Center was the tallest structure on the West Coast; as of 2017 , it is the fourth-tallest, behind buildings in Los Angeles and San Francisco.', 'Bank of America Tower (Phoenix) | The Bank of America Tower is a highrise in downtown Phoenix, Arizona. The tower is the centerpiece of the Collier Center, a multi-use office and entertainment complex. The tower was completed in 2000 and serves as the state headquarters for Bank of America. It rises 360 feet (110 m), topping out at 23 floors. It was designed in the postmodern style by Opus Architects and Engineers.', \"Bank of America Plaza (St. Louis) | The Bank of America Plaza is an award-winning skyscraper located in Downtown St. Louis, Missouri. Formerly Boatmen's Bancshares of St. Louis and First National Bank, the tower is 384 ft (117m) tall and has 31 floors. Built in 1982, it comprises 750000 sqft , and has a view of the downtown skyline. It is the fourth largest office building in Downtown St. Louis.\"]\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to determine the height of both buildings. The Empire State Building is 1,454 ft (including its antenna), while the Bank of America Tower in Phoenix is 360 ft tall.\n",
      "Answer: Empire State Building\n",
      "Context: ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.']\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Reasoning: Let's think step by step in order to identify the actress known for her debut in \"Kids\" and her involvement in Voto Latino. We know from the context that Rosario Dawson made her film debut in \"Kids\" and is also mentioned as a political activist. Therefore, she is likely the co-founder of Voto Latino.\n",
      "Answer: Rosario Dawson\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "DATASET SUMMARY: A description of the dataset that we are using.\n",
      "\n",
      "PROGRAM CODE: Language model program designed to solve a particular task.\n",
      "\n",
      "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "\n",
      "MODULE: The module to create an instruction for.\n",
      "\n",
      "TASK DEMO(S): Example inputs/outputs of our module.\n",
      "\n",
      "BASIC INSTRUCTION: Basic instruction.\n",
      "\n",
      "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "---\n",
      "\n",
      "DATASET SUMMARY: The dataset consists of various questions and their corresponding answers, primarily focusing on specific individuals, notable events, and comparative queries within multiple domains including music, film, and history. The examples highlight connections between people, events, and their relevance in their respective fields, showcasing occurrences from different periods and categories. Summary: The dataset reveals a diverse compilation of questions that cover a range of topics including notable figures in music, film, and historical events. Key insights indicate a focus on individual achievements, comparisons between significant entities, and the mapping of events to their historical context.\n",
      "\n",
      "PROGRAM CODE:\n",
      "StringSignature(context, question -> rationale, answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    rationale = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "class BaselineRAG(dspy.Module):\n",
      "    def __init__(self, num_passages=3):\n",
      "        super().__init__()\n",
      "\n",
      "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
      "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
      "\n",
      "    def forward(self, question):\n",
      "        context = self.retrieve(question).passages\n",
      "        prediction = self.generate_answer(context=context, question=question)\n",
      "        return dspy.Prediction(context=context, answer=prediction.answer, rationale=prediction.rationale)\n",
      "\n",
      "\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve fact-based question-answering tasks by leveraging a retrieval-augmented generation (RAG) approach. It utilizes a context of relevant information to provide concise answers to specific questions while also generating a rationale for the answers based on logical reasoning. The program works as follows: 1. **Context Retrieval**: When a question is posed, the program first retrieves a set of relevant passages (or context) that may contain information necessary to answer the question. This is done using a retrieval module that fetches a specified number of passages (in this case, three) based on the question. 2. **Answer Generation**: After retrieving the context, the program employs a chain-of-thought reasoning mechanism to process the context\n",
      "\n",
      "MODULE: Predict(context, question) -> rationale, answer\n",
      "\n",
      "TASK DEMO(S):\n",
      "Context: ['The Victorians | The Victorians - Their Story In Pictures is a 2009 British documentary series which focuses on Victorian art and culture. The four-part series is written and presented by Jeremy Paxman and debuted on BBC One at 9:00pm on Sunday 15 February 2009.', 'Victorian (comics) | The Victorian is a 25-issue comic book series published by Penny-Farthing Press and starting in 1999. The brainchild of creator Trainor Houghton, the series included a number of notable script writers and illustrators, including Len Wein, Glen Orbik and Howard Chaykin.', 'The Great Victorian Collection | The Great Victorian Collection, published in 1975, is a novel by Northern Irish-Canadian writer Brian Moore. Set in Carmel, California, it tells the story of a man who dreams that the empty parking lot he can see from his hotel window has been transformed by the arrival of a collection of priceless Victoriana on display in a vast open-air market. When he awakes he finds that he can no longer distinguish the dream from reality.']\n",
      "Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\n",
      "Reasoning: Let's think step by step in order to determine the birth year of the author. The documentary series \"The Victorians\" is written by Jeremy Paxman. Jeremy Paxman was born in 1950.\n",
      "Answer: 1950\n",
      "Context: ['Columbia Center | The Columbia Center, formerly named the Bank of America Tower and Columbia Seafirst Center, is a skyscraper in downtown Seattle, Washington. The 76-story structure is the tallest building in Seattle and the state of Washington, reaching a height of 937 ft . At the time of its completion, the Columbia Center was the tallest structure on the West Coast; as of 2017 , it is the fourth-tallest, behind buildings in Los Angeles and San Francisco.', 'Bank of America Tower (Phoenix) | The Bank of America Tower is a highrise in downtown Phoenix, Arizona. The tower is the centerpiece of the Collier Center, a multi-use office and entertainment complex. The tower was completed in 2000 and serves as the state headquarters for Bank of America. It rises 360 feet (110 m), topping out at 23 floors. It was designed in the postmodern style by Opus Architects and Engineers.', \"Bank of America Plaza (St. Louis) | The Bank of America Plaza is an award-winning skyscraper located in Downtown St. Louis, Missouri. Formerly Boatmen's Bancshares of St. Louis and First National Bank, the tower is 384 ft (117m) tall and has 31 floors. Built in 1982, it comprises 750000 sqft , and has a view of the downtown skyline. It is the fourth largest office building in Downtown St. Louis.\"]\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Reasoning: Let's think step by step in order to determine the height of both buildings. The Empire State Building is 1,454 ft (including its antenna), while the Bank of America Tower in Phoenix is 360 ft tall.\n",
      "Answer: Empire State Building\n",
      "Context: ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.']\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Reasoning: Let's think step by step in order to identify the actress known for her debut in \"Kids\" and her involvement in Voto Latino. We know from the context that Rosario Dawson made her film debut in \"Kids\" and is also mentioned as a political activist. Therefore, she is likely the co-founder of Voto Latino.\n",
      "Answer: Rosario Dawson\n",
      "\n",
      "\n",
      "BASIC INSTRUCTION: Answer questions with short factoid answers.\n",
      "\n",
      "PROPOSED INSTRUCTION:\u001B[32m Provide concise and accurate answers to fact-based questions by first analyzing the relevant context, then applying logical reasoning to derive the answer. Ensure that the response includes a brief rationale explaining the thought process behind the answer.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Provide concise and accurate answers to fact-based questions by first analyzing the relevant context, then applying logical reasoning to derive the answer. Ensure that the response includes a brief rationale explaining the thought process behind the answer.\n",
      "Average Metric: 39.00 / 100 (39.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 286.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 39 / 100 (39.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 39.0\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "/Users/riccardo.belluzzo/Documents/Tasks/open-source/dspy-demo-public/dspy-demo/dspy-env/lib/python3.10/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 1 / 7 ==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Propose a detailed instruction that guides the Language Model to effectively analyze the provided context and answer comparative questions about notable figures or events, ensuring clarity in reasoning and conciseness in the final answer. Include a reminder to check the birthdates or relevant details to establish accurate comparisons.\n",
      "\n",
      "**PROPOSED INSTRUCTION:** \n",
      "\n",
      "\"Given the provided context containing facts about notable individuals or events, analyze the information carefully to answer the specific comparative question. Ensure that your reasoning is clear and logical by outlining the relevant details step by step. Focus on key dates or significant achievements to establish comparisons accurately. Finally, provide a concise factoid answer that directly addresses the question posed.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 12.00 / 25 (48.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 241.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 48.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1'].\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 2 / 7 ==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 16.00 / 25 (64.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 364.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 16 / 25 (64.0%)\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 64.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 5'].\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 3 / 7 ==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Provide concise, fact-based answers to the following questions, using the given context to support your reasoning. Please ensure that your responses are clear and directly address the question asked.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "\n",
      "verage Metric: 9.00 / 25 (36.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 363.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 36.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 2'].\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0, 36.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 4 / 7 ==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "\n",
      "verage Metric: 11.00 / 25 (44.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 352.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 44.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 5'].\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0, 36.0, 44.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 5 / 7 ==\n",
      "2024/12/09 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: You are a knowledgeable historian and trivia expert. Answer the following questions with concise factoid answers based on the provided context, ensuring to highlight key details and connections relevant to the inquiry.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 217.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 4'].\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0, 36.0, 44.0, 40.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 6 / 7 ==\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Propose a detailed instruction that guides the Language Model to effectively analyze the provided context and answer comparative questions about notable figures or events, ensuring clarity in reasoning and conciseness in the final answer. Include a reminder to check the birthdates or relevant details to establish accurate comparisons.\n",
      "\n",
      "**PROPOSED INSTRUCTION:** \n",
      "\n",
      "\"Given the provided context containing facts about notable individuals or events, analyze the information carefully to answer the specific comparative question. Ensure that your reasoning is clear and logical by outlining the relevant details step by step. Focus on key dates or significant achievements to establish comparisons accurately. Finally, provide a concise factoid answer that directly addresses the question posed.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 9.00 / 23 (39.1%):  88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 22/25 [00:00<00:00, 278.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 ERROR dspy.utils.parallelizer: Error processing item Example({'question': \"For which college team did this American professional basketball player for the Miami Heat of the National Basketball Association (NBA) who earned praise for being the NBA's leading rebounder during the 2016–17 Miami Heat season play?\", 'answer': 'the Marshall Thundering Herd'}) (input_keys={'question'}): 'NoneType' object has no attribute 'strip'. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 24 (37.5%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 302.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.evaluate.evaluate: Average Metric: 9.0 / 25 (36.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 36.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 1'].\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0, 36.0, 44.0, 40.0, 36.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: == Minibatch Trial 7 / 7 ==\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Provide concise and accurate answers to fact-based questions by first analyzing the relevant context, then applying logical reasoning to derive the answer. Ensure that the response includes a brief rationale explaining the thought process behind the answer.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 13.00 / 25 (52.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 383.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.evaluate.evaluate: Average Metric: 13 / 25 (52.0%)\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 52.0 on minibatch of size 25 with parameters ['Predictor 0: Instruction 6'].\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [48.0, 64.0, 36.0, 44.0, 40.0, 36.0, 52.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 39.0\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===========================\n",
      "\n",
      "\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Full Eval 1 =====\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 54.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "verage Metric: 41.00 / 100 (41.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 300.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.evaluate.evaluate: Average Metric: 41 / 100 (41.0%)\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: \u001B[92mNew best full eval score!\u001B[0m Score: 41.0\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [39.0, 41.0]\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 41.0\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2024/12/09 13:50:24 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 41.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 50 (42.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 279.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 13:50:24 INFO dspy.evaluate.evaluate: Average Metric: 21 / 50 (42.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>gold_titles</th>\n",
       "      <th>context</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>rationale</th>\n",
       "      <th>answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td>no</td>\n",
       "      <td>{Cangzhou, Qionghai}</td>\n",
       "      <td>['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...</td>\n",
       "      <td>No, only Cangzhou is.</td>\n",
       "      <td>determine the location of both cities. Cangzhou is explicitly ment...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who conducts the draft in which Marc-Andre Fleury was drafted to t...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>{2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}</td>\n",
       "      <td>['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...</td>\n",
       "      <td>National Hockey League</td>\n",
       "      <td>identify the organization responsible for the expansion draft. The...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wings entered a new era, following the retirement of which Can...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>{Steve Yzerman, 2006–07 Detroit Red Wings season}</td>\n",
       "      <td>['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...</td>\n",
       "      <td>Steve Yzerman</td>\n",
       "      <td>identify the player being referred to. The context states that the...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What river is near the Crichton Collegiate Church?</td>\n",
       "      <td>the River Tyne</td>\n",
       "      <td>{Crichton Collegiate Church, Crichton Castle}</td>\n",
       "      <td>[\"Crichton Collegiate Church | Crichton Collegiate Church is situa...</td>\n",
       "      <td>River Tyne</td>\n",
       "      <td>identify the relevant geographical features. The context mentions ...</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...</td>\n",
       "      <td>King Alfred the Great</td>\n",
       "      <td>{Æthelweard (son of Alfred), Ealhswith}</td>\n",
       "      <td>[\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...</td>\n",
       "      <td>Alfred the Great</td>\n",
       "      <td>identify the correct English king associated with Ealhswith and he...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0         Are both Cangzhou and Qionghai in the Hebei province of China?   \n",
       "1  Who conducts the draft in which Marc-Andre Fleury was drafted to t...   \n",
       "2  The Wings entered a new era, following the retirement of which Can...   \n",
       "3                     What river is near the Crichton Collegiate Church?   \n",
       "4  In the 10th Century A.D. Ealhswith had a son called Æthelweard by ...   \n",
       "\n",
       "           example_answer  \\\n",
       "0                      no   \n",
       "1  National Hockey League   \n",
       "2           Steve Yzerman   \n",
       "3          the River Tyne   \n",
       "4   King Alfred the Great   \n",
       "\n",
       "                                                      gold_titles  \\\n",
       "0                                            {Cangzhou, Qionghai}   \n",
       "1  {2017 NHL Expansion Draft, 2017–18 Pittsburgh Penguins season}   \n",
       "2               {Steve Yzerman, 2006–07 Detroit Red Wings season}   \n",
       "3                   {Crichton Collegiate Church, Crichton Castle}   \n",
       "4                         {Æthelweard (son of Alfred), Ealhswith}   \n",
       "\n",
       "                                                                 context  \\\n",
       "0  ['Cangzhou | Cangzhou () is a prefecture-level city in eastern Heb...   \n",
       "1  ['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Peng...   \n",
       "2  ['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, ...   \n",
       "3  [\"Crichton Collegiate Church | Crichton Collegiate Church is situa...   \n",
       "4  [\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-cent...   \n",
       "\n",
       "              pred_answer  \\\n",
       "0   No, only Cangzhou is.   \n",
       "1  National Hockey League   \n",
       "2           Steve Yzerman   \n",
       "3              River Tyne   \n",
       "4        Alfred the Great   \n",
       "\n",
       "                                                               rationale  \\\n",
       "0  determine the location of both cities. Cangzhou is explicitly ment...   \n",
       "1  identify the organization responsible for the expansion draft. The...   \n",
       "2  identify the player being referred to. The context states that the...   \n",
       "3  identify the relevant geographical features. The context mentions ...   \n",
       "4  identify the correct English king associated with Ealhswith and he...   \n",
       "\n",
       "  answer_exact_match  \n",
       "0                     \n",
       "1          ✔️ [True]  \n",
       "2          ✔️ [True]  \n",
       "3          ✔️ [True]  \n",
       "4                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = MIPROv2(\n",
    "    metric=dspy.evaluate.answer_exact_match,\n",
    "    auto=\"light\",                      # Can choose between light, medium, and heavy optimization runs\n",
    "    verbose=True\n",
    ")\n",
    "optimized_program = optimizer.compile(\n",
    "    baseline,\n",
    "    trainset=train_set,\n",
    "    max_bootstrapped_demos=0,           # setting this to 0 to optimize only the instruction\n",
    "    max_labeled_demos=0,                # setting this to 0 to optimize only the instructions\n",
    "    requires_permission_to_run=True\n",
    ")\n",
    "\n",
    "optimized_program.save(\"compiled_programs/MIPROv2_program.json\")\n",
    "\n",
    "evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "You are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Sasha Alexander | Suzana S. Drobnjaković Ponti (born May 17, 1973), known by her stage name Sasha Alexander, is a Serbian-American actress. She played Gretchen Witter on \"Dawson's Creek\" and has acted in films including \"Yes Man\" (2008) and \"He's Just Not That Into You\" (2009). Alexander played Caitlin Todd for the first two seasons of \"NCIS\". From July 2010 through September 2016, Alexander starred as Maura Isles in the TNT series \"Rizzoli & Isles\".»\n",
      "[2] «The Hour of the Star | The Hour of the Star (\"A hora da estrela\") is a novel by Clarice Lispector published in 1977, shortly after the author's death. In 1985, the novel was adapted by Suzana Amaral into a film of the same name, which won the Silver Bear for Best Actress in the 36th Berlin International Film Festival of 1986. It has been translated into English twice by New Directions Publishing with Giovanni Pontiero's 1992 translation followed by Benjamin Moser's version in 2011.»\n",
      "[3] «A Sucessora (telenovela) | A Sucessora was a Brazilian telenovela written by Manoel Carlos based on the homonym novel published by Carolina Nabuco in 1934. It was aired from 9 October 1978 to 2 March 1979, comprised 125 episodes and starred Suzana Vieira, Rubens de Falco, and Nathalia Timberg.»\n",
      "\n",
      "Question: Suzana S. Drobnjaković Ponti acted in a film loosely based on a book by who?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001B[32m identify the relevant information. First, we see that Sasha Alexander, whose real name is Suzana S. Drobnjaković Ponti, acted in films including \"Yes Man\" and \"He's Just Not That Into You.\" However, the context does not specify that these films are based on books. The second context discusses \"The Hour of the Star,\" which was adapted into a film by Suzana Amaral, but does not mention Sasha Alexander. The third context is about \"A Sucessora,\" a telenovela based on a novel by Carolina Nabuco, which also does not relate to Sasha Alexander. Therefore, we need to focus on films that Sasha Alexander has acted in and any related adaptations.\n",
      "\n",
      "Answer: Unknown author\u001B[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nYou are a knowledgeable trivia expert who specializes in providing concise and accurate answers to fact-based questions. Use the provided context to identify the relevant information and respond with a brief answer, ensuring clarity and precision.\\n\\n---\\n\\nFollow the following format.\\n\\nContext: may contain relevant facts\\n\\nQuestion: ${question}\\n\\nReasoning: Let\\'s think step by step in order to ${produce the answer}. We ...\\n\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nContext:\\n[1] «Sasha Alexander | Suzana S. Drobnjaković Ponti (born May 17, 1973), known by her stage name Sasha Alexander, is a Serbian-American actress. She played Gretchen Witter on \"Dawson\\'s Creek\" and has acted in films including \"Yes Man\" (2008) and \"He\\'s Just Not That Into You\" (2009). Alexander played Caitlin Todd for the first two seasons of \"NCIS\". From July 2010 through September 2016, Alexander starred as Maura Isles in the TNT series \"Rizzoli & Isles\".»\\n[2] «The Hour of the Star | The Hour of the Star (\"A hora da estrela\") is a novel by Clarice Lispector published in 1977, shortly after the author\\'s death. In 1985, the novel was adapted by Suzana Amaral into a film of the same name, which won the Silver Bear for Best Actress in the 36th Berlin International Film Festival of 1986. It has been translated into English twice by New Directions Publishing with Giovanni Pontiero\\'s 1992 translation followed by Benjamin Moser\\'s version in 2011.»\\n[3] «A Sucessora (telenovela) | A Sucessora was a Brazilian telenovela written by Manoel Carlos based on the homonym novel published by Carolina Nabuco in 1934. It was aired from 9 October 1978 to 2 March 1979, comprised 125 episodes and starred Suzana Vieira, Rubens de Falco, and Nathalia Timberg.»\\n\\nQuestion: Suzana S. Drobnjaković Ponti acted in a film loosely based on a book by who?\\n\\nReasoning: Let\\'s think step by step in order to\\x1b[32m identify the relevant information. First, we see that Sasha Alexander, whose real name is Suzana S. Drobnjaković Ponti, acted in films including \"Yes Man\" and \"He\\'s Just Not That Into You.\" However, the context does not specify that these films are based on books. The second context discusses \"The Hour of the Star,\" which was adapted into a film by Suzana Amaral, but does not mention Sasha Alexander. The third context is about \"A Sucessora,\" a telenovela based on a novel by Carolina Nabuco, which also does not relate to Sasha Alexander. Therefore, we need to focus on films that Sasha Alexander has acted in and any related adaptations.\\n\\nAnswer: Unknown author\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
